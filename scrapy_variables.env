# lista zmiennych do wszystkich algorytmów Scrapy


#dane do logowania do bazy
hostname = "localhost"
dbname = "tuinwestor"
uname = "tuinwestor"
pwd = "qCxcUjMLL0JA3"


#Nazwy tabel
#companies_isin
table_companies_isin = "companies_isin"
#companies
table_companies = "companies"
#companies_info
table_companies_info = "companies_info"
#config_table
table_config_table = "config_table"
#aalerts_backend
table_aalerts_backend = "aalerts_backend"
#fma_cms_category_word_pairs
table_fma_cms_category_word_pairs = "fma_cms_category_word_pairs"
#fma_cms_category_words
table_fma_cms_category_words = "fma_cms_category_words"
#fma_cms_categories
table_fma_cms_categories = "fma_cms_categories"
#fma_cms_alert_categories
table_fma_cms_alert_categories = "fma_cms_alert_categories"
#fma_cms_sectors
table_fma_cms_sectors = "fma_cms_sectors"
#data
table_data = "data"  #data bo dla transakcji insiderów, ale potem przemyśleć jeśli podmiata skryptów do ESPI / EBI
#data_table
table_data_table = "data_table"
#data_full
table_data_full = "data_full"
#data_file
table_data_file = "data_file"
#sources_reports
table_sources_reports = "sources_reports"

#JOBS LISTINGS
#companies_profiles
table_job_offers_companies = "job_offers_companies"
#companies_profiles_jobs
table_companies_profiles_jobs = "companies_profiles_jobs"

#PDF INSIDER TRANSACTIONS
#transactions_share_subcat
table_transactions_share_subcat = "transactions_share_subcat"
#transactions_pdf_files
table_transactions_pdf_files = "transactions_pdf_files"
#transactions_pdf_rejected
table_transactions_pdf_rejected = "transactions_pdf_rejected"
#transactions_pdf_scanned
table_transactions_pdf_scanned = "transactions_pdf_scanned"

#GAMING TABELE
table_gaming_add_comp = "gaming_add_comp"
table_gaming_all_data = "gaming_all_data"
table_gaming_competitors = "gaming_competitors"
table_gaming_dev_pub_pl = "gaming_dev_pub_pl"
table_gaming_featured = "gaming_featured"
table_gaming_featured_pl = "gaming_featured_pl"
table_gaming_games_dat_daily = "gaming_games_dat_daily"
table_gaming_games_dat_desc = "gaming_games_dat_desc"
table_gaming_games_dat_desc_daily = "gaming_games_dat_desc_daily"
table_gaming_genres = "gaming_genres"
table_gaming_steam_changes_pl = "gaming_steam_changes_pl"
table_gaming_steam_ids = "gaming_steam_ids"
table_gaming_steam_ids_redirected = "gaming_steam_ids_redirected"
table_gaming_steam_wishlisted = "gaming_steam_wishlisted"
table_gaming_steam_wishlisted_pl = "gaming_steam_wishlisted_pl"

#News Module
table_news_companies_keywords_excluded = "news_companies_keywords_excluded"  #słowa wykluczone jak OC i AC, AC Milan
table_news_companies_keywords = "news_companies_keywords"  #słowa kluczowe słów
table_sources_news_rss = "sources_news_rss"  #źródła
table_news_exception_wform = "news_exception_wform"  #wyjątki słowne - analityk, ekspert..
table_news_companies_exception = "news_companies_exception"  #wyjątki dla spółek analityka dla Alior Bank itp..
table_news_companies_rejected = "news_companies_rejected"  #odrzucone newsy
table_news_companies_content = "news_companies_content"  #treść artykułów, summary..
table_news_companies_company = "news_companies_company"  #newsy wzmianki o spółkach
table_news_companies_all = "news_companies_all"  #newsy w których są wzmianki o spółkach (unikalne)
table_news_all_exceptions = "news_all_exceptions"  #wyjątki do oczyszczania newsów - jak Drogi użytkowniku! RODO...
table_news_importance_name = "news_importance_name"  #nazwy stopni ważności newsów
table_zz_polish_word_dict = "zz_polish_word_dict"  #odmiany polskich słów

table_news_all = "news_all"  #wszystkie pobrane newsy z gazet i portali w bazie




#zmienne do skryptu
#GENERAL VARIABLES
polish_chars = "{'ą': 'a', 'ż': 'z', 'ć': 'c', 'ó': 'o', 'ś': 's', 'ł': 'l', 'ę': 'e', 'ń': 'n', 'ź': 'z'}"


#COMPANY_LIST
#ile musi zostać minimum wykrytych spółek w tabeli na infostrefie, aby skrypt wyzerował aktywne spółki i nadał nowe
companies_min = 650
#ogólne zmienne
infostrefa_companies_url = "https://infostrefa.com/infostrefa/pl/spolki"
bankier_gpw_companies_url = "https://www.bankier.pl/gielda/notowania/akcje"
bankier_nc_companies_url = "https://www.bankier.pl/gielda/notowania/new-connect"

#COMPANY_PAGE
#linki do profili internetowych
tradingview_gpw = "https://pl.tradingview.com/symbols/GPW-"
tradingview_nc = "https://pl.tradingview.com/symbols/NEWCONNECT-"
biznesradar = "https://www.biznesradar.pl/notowania/"
bankier = "https://www.bankier.pl/inwestowanie/profile/quote.html?symbol="
#directory to save company's logo
logo_directory_main = "/var/www/html/tuinwestor.pl/python_work_files/company_page/logos/comp_id_"
logo_directory_dev = "/var/www/html/tuinwestor.pl/python_work_files/company_page/logos_dev/comp_id__"
logo_directory_other = "/var/www/html/tuinwestor.pl/python_work_files/company_page/logos_other/comp_id_"
#whether the logo will be downloaded
download_logo = 0  #0 >> do not download; 1 >> download
get_url_logo = 1  #1 >> yes, get logo url (default); 0 >> not

#COMPANY_PROFILES_JOBS
# ile bierzemy linków z pracuj_pl za jednym odpalenie skryptu
take_n_jobs = 7

#RAPORTY ESPI_EBI
dowload_files_to_disk = 0
saving_espi_ebi_files_to_disk_path = "/var/www/html/tuinwestor.pl/python_work_files/company_page/zapisywane_pliki/files_espi_ebi"

#PDF FILES - TRANSACTIONS
pdfs_subcat_dict = "{2: 'stanowisko', 3: 'opis instrumentu', 4: 'rodzaj', 6: 'miejsce'}"
pdfs_currency_lst = "['pln', 'zł', 'złoty', 'złotego', 'zl', 'eur']"
pdfs_cat_id = 16
pdf_limit_batchsize = 100

#GAMING
#url do gier wyróżnionych na tablicy steam
gaming_url_featured_categories = "https://store.steampowered.com/api/featuredcategories/"
#link do bazy na steam ze wszystkimi idkami gier
gaming_url_ISteamApps_GetAppList = "https://api.steampowered.com/ISteamApps/GetAppList/v2/"
gaming_url_popular_wishlist = "https://store.steampowered.com/search/?filter=popularwishlist&page=1"
#bazowy url do danych ze steamspy
gaming_url_steamspy_data = "https://steamspy.com/api.php"
#szczegóły do gier z bazy steam
gaming_url_steam_powered_appdetails = "http://store.steampowered.com/api/appdetails/"
#bazowy link do strony z community data o grach - liczba followersów itp
gaming_url_community_stats = "https://steamcommunity.com/games/"

#kolumny do dziennej tabeli - określają filtrowanie na mniejszy df z dużego df ze wszystkimi danymi
gaming_columns_daily = "['appid', 'positive', 'negative', 'reviews_score', 'average_forever', 'average_2weeks', 'ccu', 'metacritic_score',
                        'recommendations', 'followers', 'members_online', 'members_in_game', 'updated']"

gaming_columns_monthly = "['appid', 'name', 'developer', 'publisher', 'price', 'initialprice', 'discount', 'currency', 'owners_min', 'owners_max',
                        'languages', 'languages_no', 'genre', 'tags', 'type', 'short_description', 'metacritic_link', 'header_image', 'website',
                        'platforms', 'categories', 'pubdate', 'incomplete_date', 'pubdate_string', 'coming_soon', 'updated']"

gaming_col_names_raw = "['appid', 'positive', 'negative', 'userscore', 'owners', 'average_forever', 'average_2weeks', 'ccu',
                        'recommendations', 'name', 'developers', 'publishers', 'price', 'initialprice', 'discount', 'price_overview',
                        'supported_languages', 'genres', 'tags', 'short_description', 'metacritic', 'header_image', 'website',
                        'platforms', 'categories', 'release_date', 'type']"

#maksymalna liczba dziennych pobrań nowych gier ze steam applist
gaming_max_to_update = "2000"
#liczba odpytań do bazy z jaką zaczynamy nowy dzień - jeśli odpalany skrypt jest kilka razy dziennie to odpytania się dodają
gaming_requests_counter = "0"
#maksymalny dzienn limit odpytań do bazy steam - strony internetowej, steamspy itd..
gaming_daily_request_limit = "10000"
#liczba wierszy jaka jest zaciągana do tabeli zapisującej dane o konkurencyjnych grach według genre
gaming_number_rows_competitors = "1400"



#NEWSY
#maksymalna liczba newsów znajdujących się w ogólnej tabeli z newsami ze wszystkich źródeł
news_max_rows_table_news_all = "200000"
#minimalna liczba spółek do wspomnienia w jednym artykule, aby został on zakwalifikowany do "omówienie spółek"
news_min_comp_multi_news = "4"
#czas po którym aktualizowane są ponownie odmiany nazwy spółki na bazie zgromadzonych newsów - tauron, tauronem...
news_shorter_timeframe = "30"
news_longer_timeframe = "90"
#liczba znaków do wyświetlenia w zajawce newsa - obcinane do ostatniego słowa
news_display_text_chars = "250"
#minimalna liczba newsów podobnych, aby temat został uznany za ważny
news_rep_of_imp_news = "3"
#liczba dni wstecz od jaich pobierane są dane zmienne dla importance, rank lub similarity
news_n_days_before = "1"
#procent podobieństwa między tekstami aby artykuły zostały uznane za podobne
news_article_sim = "0.32"
news_summary_sim = "0.32"
news_title_sim = "0.90"